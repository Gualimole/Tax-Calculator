{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from collections import OrderedDict\n",
    "import taxcalc as tc\n",
    "\n",
    "\n",
    "INPUT_FILENAME = 'test_in.md'\n",
    "OUTPUT_FILENAME = 'test_out.md'\n",
    "\n",
    "# CURDIR_PATH = os.path.abspath(os.path.dirname(__file__))\n",
    "CURDIR_PATH = os.path.abspath('')\n",
    "\n",
    "TAXCALC_PATH = os.path.join(CURDIR_PATH, '..', 'taxcalc')\n",
    "\n",
    "# INPUT_PATH = os.path.join(CURDIR_PATH, INPUT_FILENAME)\n",
    "# Use TCJA to determine whether policies change in 2026.\n",
    "TCJA_PATH = os.path.join(CURDIR_PATH,'../taxcalc/reforms/TCJA.json')\n",
    "POLICY_PATH = os.path.join(TAXCALC_PATH, 'policy_current_law.json')\n",
    "IOVARS_PATH = os.path.join(TAXCALC_PATH, 'records_variables.json')\n",
    "CONSUMPTION_PATH = os.path.join(TAXCALC_PATH, 'consumption.json')\n",
    "GROWDIFF_PATH = os.path.join(TAXCALC_PATH, 'growdiff.json')\n",
    "INPUT_PATH = os.path.join(CURDIR_PATH, INPUT_FILENAME)\n",
    "OUTPUT_PATH = os.path.join(CURDIR_PATH, OUTPUT_FILENAME)\n",
    "\n",
    "START_YEAR = 2013\n",
    "END_YEAR_SHORT = 2020\n",
    "END_YEAR_LONG = 2027\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Contains high-level logic of the script.\n",
    "    \"\"\"\n",
    "    # read INPUT file into text variable\n",
    "    with open(INPUT_PATH, 'r') as ifile:\n",
    "        text = ifile.read()\n",
    "\n",
    "    # augment text variable with do-not-edit warning\n",
    "    old = '<!-- #WARN# -->'\n",
    "    new = ('<!-- *** NEVER EDIT THIS FILE BY HAND *** -->\\n'\n",
    "           '<!-- *** INSTEAD EDIT uguide.htmx FILE *** -->')\n",
    "    text = text.replace(old, new)\n",
    "\n",
    "    # augment text variable with top button code\n",
    "    # topbtn_filename = os.path.join(CURDIR_PATH, 'topbtn.htmx')\n",
    "    # with open(topbtn_filename, 'r') as topbtn_file:\n",
    "    #     topbtn = topbtn_file.read()\n",
    "    # old = '<!-- #TOP# -->'\n",
    "    # text = text.replace(old, topbtn)\n",
    "\n",
    "    params_dict = reformat_params()\n",
    "    # augment text variable with information from JSON files\n",
    "    text = policy_params(POLICY_PATH, text, params_dict)\n",
    "    import pdb; pdb.set_trace()\n",
    "    text = io_variables('read', IOVARS_PATH, text)\n",
    "    text = io_variables('calc', IOVARS_PATH, text)\n",
    "    text = assumption_params('consumption', CONSUMPTION_PATH, text)\n",
    "    text = assumption_params('growdiff', GROWDIFF_PATH, text)\n",
    "\n",
    "    # write text variable to OUTPUT file\n",
    "    with open(OUTPUT_PATH, 'w') as ofile:\n",
    "        ofile.write(text)\n",
    "\n",
    "    # normal return code\n",
    "    return 0\n",
    "# end of main function code\n",
    "\n",
    "\n",
    "def reformat_params():\n",
    "    \"\"\"\n",
    "    Translates ParamTools-style policy_current_law.json\n",
    "    to a dictionary that resembles the old Tax-Calculator\n",
    "    parameter schema\n",
    "    \"\"\"\n",
    "    # Parameters that were changed by TCJA will be extended through\n",
    "    # 2026 in the uguide\n",
    "    tcja = tc.Policy.read_json_reform(TCJA_PATH)\n",
    "\n",
    "    pol = tc.Policy()\n",
    "    pol.clear_state()\n",
    "    years_short = list(range(START_YEAR, END_YEAR_SHORT))\n",
    "    years_long = list(range(START_YEAR, END_YEAR_LONG))\n",
    "    pol.set_year(years_long)\n",
    "    params = pol.specification(serializable=True, sort_values=True)\n",
    "\n",
    "    # Create parameter dictionary that resembles old Tax-Calculator\n",
    "    # parameter schema\n",
    "    params_dict = {}\n",
    "    for param in params.keys():\n",
    "        if param in tcja.keys():\n",
    "            years = years_long\n",
    "        else:\n",
    "            years = years_short\n",
    "        params_dict[param] = {}\n",
    "        params_dict[param]['years'] = years\n",
    "        list_vals2 = []\n",
    "        for year in years:\n",
    "            list_vals1 = []\n",
    "            for idx in range(0, len(params[param])):\n",
    "                if params[param][idx]['year'] == year:\n",
    "                    list_vals1.append(params[param][idx]['value'])\n",
    "                    if params[param][idx]['year'] != params[param][idx - 1]['year']:\n",
    "                        list_vals2.append(list_vals1)\n",
    "                        params_dict[param]['values'] = list_vals2\n",
    "    return params_dict\n",
    "\n",
    "\n",
    "def policy_param_text(pname, param, params_dict):\n",
    "    \"\"\"\n",
    "    Extract info from param for pname and return as HTML string.\n",
    "    \"\"\"\n",
    "    # pylint: disable=too-many-statements,too-many-branches\n",
    "\n",
    "    sec1 = param['section_1']\n",
    "    if sec1:\n",
    "        txt = '### {}  \\n'.format(param['section_2'])\n",
    "    else:\n",
    "        txt = '### {}  \\n'.format('Not in Tax-Brain webapp')\n",
    "    txt += '#### `{}`  \\n'.format(pname)\n",
    "    txt += '_Title:_ {}  \\n'.format(param['title'])\n",
    "    txt += '_Description:_ {}  \\n'.format(param['description'])\n",
    "    if param.get('notes', ''):\n",
    "        txt += '_Notes:_ {}    \\n'.format(param['notes'])\n",
    "    txt += '_Has An Effect When Using:_ '\n",
    "    txt += ' _PUF data:_ '\n",
    "    if param['compatible_data']['puf']:\n",
    "        txt += 'True'\n",
    "    else:\n",
    "        txt += 'False'\n",
    "    txt += ' _CPS data:_ '\n",
    "    if param['compatible_data']['cps']:\n",
    "        txt += 'True  \\n'\n",
    "    else:\n",
    "        txt += 'False  \\n'\n",
    "    txt += '_Can Be Inflation Indexed:_ '\n",
    "    if param['indexable']:\n",
    "        txt += 'True'\n",
    "    else:\n",
    "        txt += 'False'\n",
    "    txt += ' _Is Inflation Indexed:_ '\n",
    "    if param['indexed']:\n",
    "        txt += 'True  \\n'\n",
    "    else:\n",
    "        txt += 'False  \\n'\n",
    "    txt += '_Value Type:_ {}  \\n'.format(param['type'])\n",
    "    txt += '_Known Values:_  \\n'\n",
    "    if len(params_dict[pname]['values'][0]) == 5:\n",
    "        txt += ' for: [single, mjoint, mseparate, headhh, widow]  \\n'\n",
    "    elif len(params_dict[pname]['values'][0]) == 4:\n",
    "        txt += ' for: [0kids, 1kid, 2kids, 3+kids]  \\n'\n",
    "    elif len(params_dict[pname]['values'][0]) == 7:\n",
    "        txt += ' for: [med, sltx, retx, cas, misc, int, char]  \\n'\n",
    "    for cyr, val in zip(params_dict[pname]['years'], params_dict[pname]['values']):\n",
    "        if len(params_dict[pname]['values'][0]) == 1:\n",
    "            txt += '{}: {}  \\n'.format(cyr, val[0])\n",
    "        else:\n",
    "            txt += '{}: {}  \\n'.format(cyr, val)\n",
    "    txt += '_Valid Range:_ '\n",
    "    validators = param.get(\"validators\", None)\n",
    "    if validators:\n",
    "        minval = validators['range']['min']\n",
    "        maxval = validators['range']['max']\n",
    "        txt += ' min = {} and max = {}  \\n'.format(minval, maxval)\n",
    "        invalid_action = validators[\"range\"].get('level', 'error')\n",
    "        txt += '_Out-of-Range Action:_ {}  \\n'.format(invalid_action)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def policy_params(path, text, params_dict):\n",
    "    \"\"\"\n",
    "    Read policy parameters from path, integrate them into text, and\n",
    "    return the integrated text.\n",
    "    \"\"\"\n",
    "    # pylint: disable=too-many-locals\n",
    "    with open(path) as pfile:\n",
    "        json_text = pfile.read()\n",
    "    params = tc.json_to_dict(json_text)\n",
    "    import pdb; pdb.set_trace()\n",
    "    assert isinstance(params, OrderedDict)\n",
    "    # construct section dict containing sec1_sec2 titles\n",
    "    concat_str = ' @ '\n",
    "    section = OrderedDict()\n",
    "    using_other_params_section = False\n",
    "    for pname in params:\n",
    "        if pname == \"schema\":\n",
    "            continue\n",
    "        param = params[pname]\n",
    "        sec1_sec2 = '{}{}{}'.format(param['section_1'],\n",
    "                                    concat_str,\n",
    "                                    param['section_2'])\n",
    "        if sec1_sec2 == concat_str:\n",
    "            using_other_params_section = True\n",
    "        elif sec1_sec2 not in section:\n",
    "            section[sec1_sec2] = 0\n",
    "    if using_other_params_section:\n",
    "        section[concat_str] = 0\n",
    "    # construct parameter text for each sec1_sec2 in section\n",
    "    for sec1_sec2 in section:\n",
    "        split_list = sec1_sec2.split(concat_str)\n",
    "        sec1 = split_list[0]\n",
    "        sec2 = split_list[1]\n",
    "        ptext = ''\n",
    "        for pname in params:\n",
    "            if pname == \"schema\":\n",
    "                continue\n",
    "            param = params[pname]\n",
    "            if sec1 == param['section_1'] and sec2 == param['section_2']:\n",
    "                ptext += policy_param_text(pname, param, params_dict)\n",
    "    return ptext\n",
    "\n",
    "\n",
    "def var_text(vname, iotype, variable):\n",
    "    \"\"\"\n",
    "    Extract info from variable for vname of iotype\n",
    "    and return info as HTML string.\n",
    "    \"\"\"\n",
    "    if iotype == 'read':\n",
    "        txt = '## `{}`'.format(vname)\n",
    "        if 'required' in variable:\n",
    "            txt += '*'\n",
    "    else:\n",
    "        txt = '## `{}`'.format(vname)\n",
    "    txt += '_Description:_ {}  \\n'.format(variable['desc'])\n",
    "    if variable['type'] == 'float':\n",
    "        vtype = 'real'\n",
    "    elif variable['type'] == 'int':\n",
    "        vtype = 'integer'\n",
    "    else:\n",
    "        msg = ('{} variable {} has '\n",
    "               'unknown type={}  \\n'.format(iotype, vname, variable['type']))\n",
    "        raise ValueError(msg)\n",
    "    txt += '_Datatype:_ {}  \\n'.format(vtype)\n",
    "    if iotype == 'read':\n",
    "        txt += '_Availability:_ {}  \\n'.format(variable['availability'])\n",
    "    txt += '_IRS Form Location:_'\n",
    "    formdict = variable['form']\n",
    "    for yrange in sorted(formdict.keys()):\n",
    "        txt += '{}: {}  \\n'.format(yrange, formdict[yrange])\n",
    "    return txt\n",
    "\n",
    "\n",
    "def io_variables(iotype, path, text):\n",
    "    \"\"\"\n",
    "    Read variables for iotype ('read' for input or 'calc' for output)\n",
    "    from path, integrate them into text, and return the integrated text.\n",
    "    \"\"\"\n",
    "    with open(path) as vfile:\n",
    "        json_text = vfile.read()\n",
    "    variables = tc.json_to_dict(json_text)\n",
    "    assert isinstance(variables, dict)\n",
    "    # construct variable text\n",
    "    vtext = ''\n",
    "    for vname in sorted(variables[iotype].keys()):\n",
    "        vtext += var_text(vname, iotype, variables[iotype][vname])\n",
    "    # integrate variable text into text\n",
    "    old = '<!-- {}@variables -->'.format(iotype)\n",
    "    text = text.replace(old, vtext)\n",
    "    return text\n",
    "\n",
    "\n",
    "def assumption_param_text(pname, ptype, param):\n",
    "    \"\"\"\n",
    "    Extract info from param for pname of ptype and return as HTML string.\n",
    "    \"\"\"\n",
    "    sec1 = param.get('section_1', '')\n",
    "    if sec1:\n",
    "        txt = '### {}'.format(param.get('section_2', ''))\n",
    "    else:\n",
    "        txt = '### {}'.format(ptype.capitalize())\n",
    "    txt += '#### `{}`  \\n'.format(pname)\n",
    "    if sec1:\n",
    "        txt += '_TB Name:_ {}  \\n'.format(param['title'])\n",
    "    else:\n",
    "        txt += '_Long Name:_ {}  \\n'.format(param['title'])\n",
    "    txt += '_Description:_ {}  \\n'.format(param['description'])\n",
    "    if param.get('notes', ''):\n",
    "        txt += '_Notes:_ {}  \\n'.format(param['notes'])\n",
    "    txt += '_Default Value:_  \\n'\n",
    "    if param.get('vi_vals', []):\n",
    "        cols = ', '.join(param['vi_vals'])\n",
    "        txt += ' for: [{}]  \\n'.format(cols)\n",
    "    for vo in param[\"value\"]:\n",
    "        labels = \" \".join(\n",
    "            f\"{label}={value}\" for label, value in vo.items()\n",
    "            if label not in (\"year\", \"value\")\n",
    "        )\n",
    "        txt += f\"{vo['year']}: {vo['value']} {labels}  \"\n",
    "    txt += '_Valid Range:_'\n",
    "    validators = param.get(\"validators\", None)\n",
    "    if validators:\n",
    "        minval = validators['range']['min']\n",
    "        maxval = validators['range']['max']\n",
    "        txt += ' min = {} and max = {}  \\n'.format(minval, maxval)\n",
    "        invalid_action = validators[\"range\"].get('level', 'error')\n",
    "        txt += '_Out-of-Range Action:_ {}  \\n'.format(invalid_action)\n",
    "    return txt\n",
    "\n",
    "\n",
    "def assumption_params(ptype, path, text):\n",
    "    \"\"\"\n",
    "    Read assumption parameters of ptype from path, integrate them into text,\n",
    "    and return the integrated text.\n",
    "    \"\"\"\n",
    "    with open(path) as pfile:\n",
    "        json_text = pfile.read()\n",
    "    params = tc.json_to_dict(json_text)\n",
    "    assert isinstance(params, OrderedDict)\n",
    "    # construct parameter text for each param\n",
    "    ptext = ''\n",
    "    for pname in params:\n",
    "        if pname == \"schema\":\n",
    "            continue\n",
    "        param = params[pname]\n",
    "        ptext += assumption_param_text(pname, ptype, param)\n",
    "    # integrate parameter text into text\n",
    "    old = '<!-- {}@parameters -->'.format(ptype)\n",
    "    text = text.replace(old, ptext)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_dict = reformat_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-2-63d26f492f05>(178)policy_params()\n",
      "-> assert isinstance(params, OrderedDict)\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "text = policy_params(POLICY_PATH, '', params_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(POLICY_PATH) as pfile:\n",
    "    json_text = pfile.read()\n",
    "params = tc.json_to_dict(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(params).transpose()[1:].join(\n",
    "    pd.DataFrame(params_dict).transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def boolstr(b):\n",
    "    if isinstance(b, pd.Series):\n",
    "        return pd.Series(np.where(b, 'True', 'False'),\n",
    "                         index=b.index)\n",
    "    if b:\n",
    "        return 'True'\n",
    "    return 'False'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paramtextdf(p):\n",
    "    \"\"\" Don't include sections - do that later.\n",
    "    \n",
    "    Args:\n",
    "        p: DataFrame representing parameters.\n",
    "    \"\"\"\n",
    "    def title(p):\n",
    "        return '####  `' + p.index + '`'\n",
    "    \n",
    "    def description(p):\n",
    "        return '_Description:_ ' + p.description\n",
    "    \n",
    "    def notes(p):\n",
    "        return np.where(p.notes == '', '', '_Notes:_ ' + p.notes)\n",
    "    \n",
    "    def effect_puf_cps_one(row):\n",
    "        return ('_Has An Effect When Using:_' +\n",
    "                ' _PUF data:_ ' + boolstr(row.compatible_data['puf']) +\n",
    "                ' _CPS data:_ ' + boolstr(row.compatible_data['cps']))\n",
    "    \n",
    "    def effect_puf_cps(p):\n",
    "        return p.apply(effect_puf_cps_one, axis=1)\n",
    "                \n",
    "    def inflation_indexed(p):\n",
    "        return ('_Can Be Inflation Indexed:_ ' + boolstr(p.indexable) +\n",
    "                ' _Is Inflation Indexed:_ ' + boolstr(p.indexed))\n",
    "        \n",
    "    def value_type(p):\n",
    "        return '_Value Type:_ ' + p.type\n",
    "    \n",
    "    def known_values_one(row):\n",
    "        # Requires non-vectorizable functions.\n",
    "        txt ='_Known Values:_  \\n'\n",
    "        nvalues = len(row['values'][0])\n",
    "        if nvalues == 5:\n",
    "            txt += ' for: [single, mjoint, mseparate, headhh, widow]  \\n'\n",
    "        elif nvalues == 4:\n",
    "            txt += ' for: [0kids, 1kid, 2kids, 3+kids]  \\n'\n",
    "        elif nvalues == 7:\n",
    "            txt += ' for: [med, sltx, retx, cas, misc, int, char]  \\n'\n",
    "        for cyr, val in zip(row['years'], row['values']):\n",
    "            if nvalues == 1:\n",
    "                val = val[0]\n",
    "            txt += str(cyr) + ': ' + str(val) + '  \\n'\n",
    "        return txt\n",
    "                         \n",
    "    def known_values(p):\n",
    "        return p.apply(known_values_one, axis=1)\n",
    "        \n",
    "    def valid_range_one(row):\n",
    "        r = row.validators['range']\n",
    "        return ('_Valid Range:_' +\n",
    "                ' min = ' + str(r['min']) +\n",
    "                ' and max = ' + str(r['max']) + '  \\n' +\n",
    "                '_Out-of-Range Action:_ ' + r.get('level', 'error'))\n",
    "    \n",
    "    def valid_range(p):\n",
    "        return p.apply(valid_range_one, axis=1)\n",
    "    \n",
    "    return (title(p) + '  \\n' +\n",
    "            description(p) + '  \\n' +\n",
    "            notes(p) + '  \\n' +\n",
    "            effect_puf_cps(p) + '  \\n' +\n",
    "            inflation_indexed(p) + '  \\n' +\n",
    "            value_type(p) + '  \\n' +\n",
    "            known_values(p) + '  \\n' +\n",
    "            valid_range(p) + '\\n\\n'\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'] = paramtextdf(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.section_1 = np.where(df.section_1 == '', 'Other Parameters (not in Tax-Brain webapp)',\n",
    "                        df.section_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "SECTION_1_ORDER = ['Parameter Indexing',\n",
    "                   'Payroll Taxes',\n",
    "                   'Social Security Taxability',\n",
    "                   'Above The Line Deductions',\n",
    "                   'Personal Exemptions',\n",
    "                   'Standard Deduction',\n",
    "                   'Nonrefundable Credits',\n",
    "                   'Child/Dependent Credits',\n",
    "                   'Itemized Deductions',\n",
    "                   'Capital Gains And Dividends',\n",
    "                   'Personal Income',\n",
    "                   'Other Taxes',\n",
    "                   'Refundable Credits',\n",
    "                   'Surtaxes',\n",
    "                   'Universal Basic Income',\n",
    "                   'Benefits',\n",
    "                   'Other Parameters (not in Tax-Brain webapp)']\n",
    "section_1_order_index = dict(zip(SECTION_1_ORDER, range(len(SECTION_1_ORDER))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['section_1_order'] = df.section_1.map(section_1_order_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPI_offset           0.0\n",
       "FICA_ss_trt          1.0\n",
       "SS_Earnings_c        1.0\n",
       "SS_Earnings_thd      1.0\n",
       "FICA_mc_trt          1.0\n",
       "                    ... \n",
       "BEN_mcare_repeal    15.0\n",
       "BEN_mcaid_repeal    15.0\n",
       "BEN_oasdi_repeal    15.0\n",
       "BEN_ui_repeal       15.0\n",
       "BEN_other_repeal    15.0\n",
       "Name: section_1_order, Length: 223, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.section_1_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CPI_offset          ## Parameter Indexing\\n\\n### Offsets\\n\\n####  ...\n",
       "FICA_ss_trt         ## Payroll Taxes\\n\\n### Social Security FICA\\n...\n",
       "SS_Earnings_c       ####  `SS_Earnings_c`  \\n_Description:_ Indivi...\n",
       "SS_Earnings_thd     ####  `SS_Earnings_thd`  \\n_Description:_ Indi...\n",
       "FICA_mc_trt         ### Medicare FICA\\n\\n####  `FICA_mc_trt`  \\n_D...\n",
       "                                          ...                        \n",
       "BEN_mcare_repeal    ####  `BEN_mcare_repeal`  \\n_Description:_ Med...\n",
       "BEN_mcaid_repeal    ####  `BEN_mcaid_repeal`  \\n_Description:_ Med...\n",
       "BEN_oasdi_repeal    ####  `BEN_oasdi_repeal`  \\n_Description:_ Soc...\n",
       "BEN_ui_repeal       ####  `BEN_ui_repeal`  \\n_Description:_ Unempl...\n",
       "BEN_other_repeal    ####  `BEN_other_repeal`  \\n_Description:_ Oth...\n",
       "Name: content_all, Length: 223, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add section titles.\n",
    "\n",
    "df['new_section_1'] = ~df.section_1.eq(df.section_1.shift())\n",
    "df['new_section_2'] = ~df.section_2.eq(df.section_2.shift()) & df.section_2 > ''\n",
    "\n",
    "df['section_1_content'] = np.where(df.new_section_1, '## ' + df.section_1 + '\\n\\n', '')\n",
    "df['section_2_content'] = np.where(df.new_section_2, '### ' + df.section_2 + '\\n\\n', '')\n",
    "\n",
    "df['content_all'] = df.section_1_content + df.section_2_content + df.content\n",
    "\n",
    "df.content_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_out.md\", 'w') as f:\n",
    "    f.write('\\n\\n'.join(df.content_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
